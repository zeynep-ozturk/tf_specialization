{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zezeko/tf_specialization/blob/master/cnns/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "fa44cf76-0c47-4dc7-f04b-b1da23f0352f"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a76bf66-6e1f-40ea-cb9e-b019090131ef"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model =  InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 05:20:39--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  63.2MB/s    in 1.3s    \n",
            "\n",
            "2020-01-15 05:20:40 (63.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6469346a-ade0-46b5-dd4c-3e561a0466f0"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "523ee786-6684-443f-9981-af4772887676"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f1e0a3f4-6bb5-44ad-b351-8343e6356c21"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 05:20:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  88.2MB/s    in 1.6s    \n",
            "\n",
            "2020-01-15 05:21:01 (88.2 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-15 05:21:03--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-01-15 05:21:04 (150 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "07b8c7e9-210e-4776-fc9f-7b7c8ed7f1a5"
      },
      "source": [
        "# Define our example directories and files\n",
        "\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join( train_dir, 'horses')\n",
        "train_humans_dir = os.path.join( train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join( validation_dir, 'horses')\n",
        "validation_humans_dir = os.path.join( validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:#\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ba4eb559-8825-4750-d283-180cc2750aa4"
      },
      "source": [
        "# Define our example directories and files\n",
        "#train_dir = '/tmp/training'\n",
        "#validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator( rescale=1./255,\n",
        "                rotation_range=40,\n",
        "                width_shift_range=0.2,\n",
        "                height_shift_range=0.2,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.2,\n",
        "                horizontal_flip=True,\n",
        "                fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale=1./255 )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6550c52-c8c9-4788-c401-4149feecb143"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose=2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 35s - loss: 0.1907 - acc: 0.9175 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0603 - acc: 0.9750 - val_loss: 0.0037 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0488 - acc: 0.9843 - val_loss: 0.0408 - val_acc: 0.9808\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0211 - acc: 0.9919 - val_loss: 0.0477 - val_acc: 0.9838\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0329 - acc: 0.9904 - val_loss: 0.3409 - val_acc: 0.9565\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0393 - acc: 0.9914 - val_loss: 0.0732 - val_acc: 0.9848\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0249 - acc: 0.9919 - val_loss: 0.0470 - val_acc: 0.9899\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0308 - acc: 0.9889 - val_loss: 0.1824 - val_acc: 0.9737\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0300 - acc: 0.9939 - val_loss: 0.0737 - val_acc: 0.9889\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0347 - acc: 0.9904 - val_loss: 0.1329 - val_acc: 0.9848\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0317 - acc: 0.9919 - val_loss: 0.1752 - val_acc: 0.9757\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0372 - acc: 0.9899 - val_loss: 0.0828 - val_acc: 0.9889\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0258 - acc: 0.9929 - val_loss: 0.3869 - val_acc: 0.9595\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0243 - acc: 0.9959 - val_loss: 0.1636 - val_acc: 0.9757\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0512 - acc: 0.9909 - val_loss: 0.2018 - val_acc: 0.9808\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0318 - acc: 0.9934 - val_loss: 0.1939 - val_acc: 0.9737\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0157 - acc: 0.9949 - val_loss: 0.1853 - val_acc: 0.9757\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0177 - acc: 0.9944 - val_loss: 0.5161 - val_acc: 0.9565\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0201 - acc: 0.9935 - val_loss: 0.7100 - val_acc: 0.9545\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0125 - acc: 0.9964 - val_loss: 0.4134 - val_acc: 0.9656\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0082 - acc: 0.9985 - val_loss: 0.5041 - val_acc: 0.9595\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.6415 - val_acc: 0.9585\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0088 - acc: 0.9970 - val_loss: 0.3961 - val_acc: 0.9656\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0157 - acc: 0.9949 - val_loss: 0.7018 - val_acc: 0.9494\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0122 - acc: 0.9965 - val_loss: 0.5863 - val_acc: 0.9534\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0184 - acc: 0.9934 - val_loss: 0.4097 - val_acc: 0.9605\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0057 - acc: 0.9975 - val_loss: 0.4607 - val_acc: 0.9575\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0181 - acc: 0.9965 - val_loss: 0.2353 - val_acc: 0.9696\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0127 - acc: 0.9949 - val_loss: 0.5911 - val_acc: 0.9524\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0140 - acc: 0.9959 - val_loss: 0.4734 - val_acc: 0.9605\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0141 - acc: 0.9965 - val_loss: 0.4470 - val_acc: 0.9605\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 24s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.6952 - val_acc: 0.9555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "3ef47091-0af9-47b6-969d-3545b79da6bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}